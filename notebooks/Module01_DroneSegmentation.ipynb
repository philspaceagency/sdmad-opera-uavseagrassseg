{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbc2fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.10.5)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.0)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
      "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n",
      "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (3.7.2)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from shapely) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio\n",
    "!pip install geopandas\n",
    "!pip install tqdm\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e4877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from rasterio.windows import Window\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d37aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.InstanceNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.skip = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.leaky_relu(self.conv(x) + self.skip(x), 0.1)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual U-Net style Autoencoder\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=3, latent_dim=256):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        #----------ENCODER----------#\n",
    "        self.enc1 = ResidualBlock(input_channels, 32)\n",
    "        self.enc2 = ResidualBlock(32, 64)\n",
    "        self.enc3 = ResidualBlock(64, 128)\n",
    "        self.enc4 = ResidualBlock(128, 256)\n",
    "        self.enc5 = ResidualBlock(256, latent_dim)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        #----------DECODER----------#\n",
    "        self.up5 = nn.ConvTranspose2d(latent_dim, 256, 2, stride=2)\n",
    "        self.dec5 = ResidualBlock(256 + 256, 256)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec4 = ResidualBlock(128 + 128, 128)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec3 = ResidualBlock(64 + 64, 64)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = ResidualBlock(32 + 32, 32)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(32, input_channels, 3, padding=1)\n",
    "        self.output_activation = nn.Tanh()\n",
    "\n",
    "def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        e5 = self.enc5(self.pool(e4))\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        d5 = self.up5(e5)\n",
    "        d5 = torch.cat([d5, e4], dim=1)\n",
    "        d5 = self.dec5(d5)\n",
    "\n",
    "        d4 = self.up4(d5)\n",
    "        d4 = torch.cat([d4, e3], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat([d3, e2], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        out = self.output_activation(self.final_conv(d2))\n",
    "        return out, e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbe10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, rgb_stack, patch_size=256, stride=16,\n",
    "                 normalize=True, valid_threshold=0.1):\n",
    "        self.rgb_stack = rgb_stack\n",
    "        self.patch_size = patch_size\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # Extract patches\n",
    "        self.patches, self.positions = self._extract_patches(stride, valid_threshold)\n",
    "\n",
    "        # Normalize if requested\n",
    "        if normalize and len(self.patches) > 0:\n",
    "            # Normalize per channel across all patches\n",
    "            n_samples = self.patches.shape[0]\n",
    "            n_channels = self.patches.shape[1]\n",
    "\n",
    "            # Reshape to (n_samples * height * width, n_channels)\n",
    "            original_shape = self.patches.shape\n",
    "            reshaped = self.patches.reshape(n_samples, n_channels, -1)  # (N, C, H*W)\n",
    "            reshaped = reshaped.transpose(0, 2, 1)  # (N, H*W, C)\n",
    "            reshaped = reshaped.reshape(-1, n_channels)  # (N*H*W, C)\n",
    "\n",
    "            # Fit and transform\n",
    "            self.scaler = StandardScaler()\n",
    "            normalized = self.scaler.fit_transform(reshaped)\n",
    "\n",
    "            # Reshape back\n",
    "            normalized = normalized.reshape(n_samples, patch_size, patch_size, n_channels)\n",
    "            normalized = normalized.transpose(0, 3, 1, 2)  # (N, C, H, W)\n",
    "\n",
    "            self.patches = normalized.astype(np.float32)\n",
    "\n",
    "    def _extract_patches(self, stride, valid_threshold):\n",
    "        \"\"\"Extract patches from RGB stack\"\"\"\n",
    "        h, w, c = self.rgb_stack.shape\n",
    "        patches = []\n",
    "        positions = []\n",
    "\n",
    "        for y in range(0, h - self.patch_size + 1, stride):\n",
    "            for x in range(0, w - self.patch_size + 1, stride):\n",
    "                patch = self.rgb_stack[y:y+self.patch_size,\n",
    "                                      x:x+self.patch_size, :]\n",
    "\n",
    "                # Check if patch has enough valid pixels (not black/zero)\n",
    "                # For RGB, we check if pixels are above a certain brightness threshold\n",
    "                valid_ratio = np.mean(patch > valid_threshold * 255) if patch.dtype == np.uint8 else np.mean(patch > valid_threshold)\n",
    "\n",
    "                if valid_ratio >= valid_threshold:\n",
    "                    # Transpose to (C, H, W) for PyTorch\n",
    "                    patch = np.transpose(patch, (2, 0, 1))\n",
    "                    patches.append(patch)\n",
    "                    positions.append((y, x))\n",
    "\n",
    "        patches = np.array(patches, dtype=np.float32)\n",
    "        print(f\"Extracted {len(patches)} valid patches\")\n",
    "\n",
    "        return patches, positions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.patches[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8144fc59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
